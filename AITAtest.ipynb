{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPdidTQr0B1hkUcjGDIH3/j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sudhanshu20004-9/AI-tech-Lab1/blob/main/AITAtest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!unzip /content/obj.zip -d /content/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYl83DPYisGv",
        "outputId": "2c5e44e0-6535-410d-b090-147f735fa028"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/obj.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/obj.zip or\n",
            "        /content/obj.zip.zip, and cannot find /content/obj.zip.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dleIgYz9hkfW"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install tensorflow opencv-python pillow\n",
        "!pip install git+https://github.com/zzh8829/yolov3-tf2.git\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "import tensorflow as tf\n",
        "from yolov3.tf import YOLOv3\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Step 1: Prepare the Dataset\n",
        "def convert_annotation(xml_file, image_width, image_height):\n",
        "    \"\"\"\n",
        "    Converts the annotation in Pascal VOC XML format to YOLO format.\n",
        "    \"\"\"\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    bboxes = []\n",
        "\n",
        "    for obj in root.iter('object'):\n",
        "        name = obj.find('name').text\n",
        "        if name == \"vehicle\":  # Filter only vehicle objects\n",
        "            # Get the bounding box coordinates\n",
        "            bndbox = obj.find('bndbox')\n",
        "            xmin = int(bndbox.find('xmin').text)\n",
        "            ymin = int(bndbox.find('ymin').text)\n",
        "            xmax = int(bndbox.find('xmax').text)\n",
        "            ymax = int(bndbox.find('ymax').text)\n",
        "\n",
        "            # Convert to YOLO format\n",
        "            x_center = (xmin + xmax) / 2.0 / image_width\n",
        "            y_center = (ymin + ymax) / 2.0 / image_height\n",
        "            width = (xmax - xmin) / float(image_width)\n",
        "            height = (ymax - ymin) / float(image_height)\n",
        "\n",
        "            # Append the vehicle annotation in YOLO format (class id, x_center, y_center, width, height)\n",
        "            bboxes.append(f\"0 {x_center} {y_center} {width} {height}\")  # 0 is the vehicle class\n",
        "\n",
        "    return bboxes\n",
        "\n",
        "# Convert annotations for all images\n",
        "image_width = 1280  # Example image width (replace with actual)\n",
        "image_height = 720  # Example image height (replace with actual)\n",
        "\n",
        "annotations_dir = '/content/dataset/annotations/'  # Path to annotations (XML)\n",
        "image_dir = '/content/dataset/images/'  # Path to images\n",
        "\n",
        "for xml_file in os.listdir(annotations_dir):\n",
        "    if xml_file.endswith(\".xml\"):\n",
        "        xml_path = os.path.join(annotations_dir, xml_file)\n",
        "        image_path = os.path.join(image_dir, xml_file.replace('.xml', '.jpg'))\n",
        "\n",
        "        yolo_annotations = convert_annotation(xml_path, image_width, image_height)\n",
        "\n",
        "        # Save the YOLO annotations to a text file\n",
        "        txt_file = os.path.join(annotations_dir, xml_file.replace('.xml', '.txt'))\n",
        "        with open(txt_file, 'w') as f:\n",
        "            for annotation in yolo_annotations:\n",
        "                f.write(f\"{annotation}\\n\")\n",
        "\n",
        "# Step 2: Set Up YOLOv3 Model\n",
        "from yolov3.tf import YOLOv3\n",
        "from yolov3.utils import load_weights\n",
        "\n",
        "# Initialize YOLOv3\n",
        "yolo = YOLOv3(classes=1)  # We have 1 class (vehicle)\n",
        "\n",
        "# Load pre-trained weights (COCO dataset, for example)\n",
        "weights_path = '/content/yolov3.weights'\n",
        "load_weights(yolo, weights_path)\n",
        "\n",
        "# Step 3: Prepare the Data Generator\n",
        "def create_data_generator(image_dir, annotations_dir, batch_size=32):\n",
        "    \"\"\"\n",
        "    Generates batches of images and labels for YOLOv3 model.\n",
        "    \"\"\"\n",
        "    image_paths = []\n",
        "    label_paths = []\n",
        "    for filename in os.listdir(annotations_dir):\n",
        "        if filename.endswith('.txt'):\n",
        "            image_paths.append(os.path.join(image_dir, filename.replace('.txt', '.jpg')))\n",
        "            label_paths.append(os.path.join(annotations_dir, filename))\n",
        "\n",
        "    def generator():\n",
        "        while True:\n",
        "            for image_path, label_path in zip(image_paths, label_paths):\n",
        "                image = cv2.imread(image_path)\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                image = cv2.resize(image, (416, 416))\n",
        "                image = np.array(image, dtype=np.float32) / 255.0  # Normalize\n",
        "\n",
        "                with open(label_path, 'r') as f:\n",
        "                    labels = f.readlines()\n",
        "\n",
        "                boxes = []\n",
        "                for label in labels:\n",
        "                    parts = label.strip().split()\n",
        "                    class_id, x_center, y_center, width, height = map(float, parts)\n",
        "                    boxes.append([x_center, y_center, width, height])\n",
        "                boxes = np.array(boxes)\n",
        "                yield (image, boxes)\n",
        "\n",
        "    return generator()\n",
        "\n",
        "# Step 4: Train YOLO Model\n",
        "batch_size = 16\n",
        "train_generator = create_data_generator(image_dir, annotations_dir, batch_size)\n",
        "\n",
        "# Compile the model (adjust learning rate and optimizer as needed)\n",
        "yolo.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='yolo_loss')\n",
        "\n",
        "# Train the model (set the number of epochs)\n",
        "yolo.fit(train_generator, steps_per_epoch=100, epochs=50)\n",
        "\n",
        "# Save the trained model\n",
        "yolo.save('vehicle_detection_yolo_model.h5')\n",
        "\n",
        "# Step 5: Run Inference on New Images\n",
        "def detect_vehicles(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image_resized = cv2.resize(image_rgb, (416, 416))  # Resize to YOLO input size\n",
        "    image_normalized = np.array(image_resized, dtype=np.float32) / 255.0  # Normalize\n",
        "\n",
        "    # Get model predictions\n",
        "    predictions = yolo.predict(np.expand_dims(image_normalized, axis=0))\n",
        "\n",
        "    # Process predictions (boxes, classes, and scores)\n",
        "    boxes, scores, classes, valid_detections = predictions\n",
        "\n",
        "    # Draw bounding boxes for detected vehicles\n",
        "    for i in range(valid_detections[0]):\n",
        "        box = boxes[0][i]\n",
        "        score = scores[0][i]\n",
        "        class_id = int(classes[0][i])\n",
        "\n",
        "        if score > 0.5 and class_id == 0:  # Filter by confidence and class ID\n",
        "            x_center, y_center, width, height = box\n",
        "            x1 = int((x_center - width / 2) * image.shape[1])\n",
        "            y1 = int((y_center - height / 2) * image.shape[0])\n",
        "            x2 = int((x_center + width / 2) * image.shape[1])\n",
        "            y2 = int((y_center + height / 2) * image.shape[0])\n",
        "\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    # Show the image with detected vehicles\n",
        "    cv2.imshow('Vehicle Detection', image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Run inference on a test image\n",
        "detect_vehicles('/content/test_image.jpg')\n"
      ]
    }
  ]
}